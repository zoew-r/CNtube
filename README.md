# CNtube ğŸ¬

Learn Traditional Chinese through Video Transcription

CNtube is a web application that helps users learn Chinese by:
1. Extracting audio from video URLs (YouTube, etc.)
2. Transcribing the audio to Traditional Chinese using OpenAI's Whisper model
3. Analyzing the transcription to extract vocabulary and grammar points using LLM

## Features

- **Video URL Processing**: Paste any video URL (YouTube supported) to extract audio
- **Speech-to-Text**: Uses Whisper model for accurate Chinese transcription
- **Traditional Chinese Output**: Ensures transcription is in Traditional Chinese (ç¹é«”ä¸­æ–‡)
- **Vocabulary Extraction**: Identifies key vocabulary with pinyin, English translations, and examples
- **Grammar Analysis**: Extracts grammar points with explanations and example sentences
- **Beautiful UI**: Clean, responsive interface for an enjoyable learning experience

## Requirements

- Python 3.10+
- FFmpeg (for audio extraction)
- OpenAI API Key (for LLM-based vocabulary/grammar analysis)

## Installation

1. Clone the repository:
```bash
git clone https://github.com/zoew-r/CNtube.git
cd CNtube
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Install FFmpeg:
- **macOS**: `brew install ffmpeg`
- **Ubuntu/Debian**: `sudo apt-get install ffmpeg`
- **Windows**: Download from [FFmpeg website](https://ffmpeg.org/download.html)

5. Set up environment variables:
```bash
cp .env.example .env
# Edit .env and add your OpenAI API key
```

## Usage

1. Start the application:
```bash
python app.py
```

2. Open your browser and navigate to `http://localhost:5000`

3. Paste a video URL (e.g., YouTube link) and click "é–‹å§‹å­¸ç¿’" (Start Learning)

4. Wait for the processing to complete:
   - Audio extraction
   - Speech-to-text transcription
   - Vocabulary and grammar analysis

5. Review the results:
   - **é€å­—ç¨¿ (Transcription)**: Full Traditional Chinese transcription
   - **è©å½™ (Vocabulary)**: Key words with pinyin, English, and examples
   - **æ–‡æ³•é» (Grammar Points)**: Grammar structures with explanations

## Project Structure

```
CNtube/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ routes.py          # API routes
â”‚   â”œâ”€â”€ video_processor.py # Video/audio extraction
â”‚   â”œâ”€â”€ transcriber.py     # Whisper transcription
â”‚   â””â”€â”€ language_analyzer.py # LLM-based analysis
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Frontend UI
â”œâ”€â”€ static/                # Static assets
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env.example          # Environment variables template
â””â”€â”€ README.md
```

## API Endpoints

- `GET /` - Main web interface
- `POST /process` - Process a video URL
  - Request: `{ "video_url": "https://..." }`
  - Response: `{ "success": true, "transcription": "...", "analysis": {...} }`
- `GET /health` - Health check endpoint

## Configuration

Environment variables (set in `.env`):
- `OPENAI_API_KEY`: Your OpenAI API key for LLM analysis
- `FLASK_SECRET_KEY`: Secret key for Flask sessions
- `FLASK_ENV`: Environment mode (development/production)

## Notes

- The Whisper model will be downloaded on first use (~140MB for base model)
- Processing time depends on video length and system resources
- Without an OpenAI API key, mock vocabulary/grammar analysis will be provided
- The app supports any video URL that yt-dlp can handle (YouTube, Vimeo, etc.)

## License

MIT License
